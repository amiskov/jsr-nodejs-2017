# Занятие №2, 5 мая
* Потоки
* Тестирование

## Зачем нужны потоки
Когда нужно обработать боьшой файл (фильм в HD, например), то загружать его в ОЗУ не выйдет (только если поставить много Гб ОЗУ). Для таких случаев придумали способ: обрабатывать данные порциями.

Если говорить о сервере, то отдавать большие файлы сразу тоже проблематично. У юзеров может быть медленный интернет и много всего может висеть в ОЗУ.

Нода получает/отправляет данные потоками — порциями данных (по 64Кб по умолчанию).

## Threads vs. Stream

* Есть [поток выполнения](https://ru.wikipedia.org/wiki/Поток_выполнения) — thread, относится к ОС.
* Есть поток данных — stream, с ними работает Нода.

В NodeJS V8 выполняет JS в 1 поток ОС (thread) и любая блокирующая операция заблокирует его и все остальные операции встанут в очередь. Потоки (streams) для обработки данных в NodeJS решают эту ситуацию.

## Потоки в NodeJS

В Ноде было реализовано уже 3 версии работы с потоками данных: stream1, stream2, stream3. Концепты не менялись, API изменился незначительно, внутри сильно переписали. Стало надежнее, лучше и безопаснее.

Потоки бывают:
* Readable — читают данные.
* Writable — записывают данные.
* Duplex, Transform — реализуют интерфейс чтения и записи на одном объекте потока. Поток архивирования, например: пишем в поток архивирования и оттуда сразу же считываем.

Конструктор потока наследует от EventEmitter-а. Помимо унаследнованных методов (`.on`, `.emit`, ...) потоки имеют свои: `.read`, `.write` и пр. У потоков есть свойство `.buffer`, куда они данные (кусочки) и сохраняют. Напрямую туда залезть нельзя.

У Readable-потоков есть 2 состояния: `paused` и `flowing`.

Поток, считав кусок данных, ждет, пока их кто-то заберет. Если они никуда не передаются, то включается режим `paused`, чтоб не засерать ОЗУ.

Перевести поток в режим `flowing` (считывать данные) можно так:
* `stream.pipe(out)` — данные кому-то нужны (`out` — выходной поток на запись), поэтому они считываются и передаются.
* `stream.on('data', chunk => ...)` — считав порцию данных срабатывает событие `data` и эта порция (`chunk`) передается в обработчик.
* `stream.resume()` (его антипод — метод `.pause()`). Практически не используется, но иногда бывает нужно именно руками управлять ходом чтения/записи.

Событие `readable` отличается от `data`. В `readable` не приходит чанк, поэтому оно не переводит поток в режим `flowing`. События `readable` означает, что в буфере появились данные и их можно считать. И чтобы данные высвободить в оработчике нужно вызвать `stream.read()`:

```js
stream.on('readable', () => {
    const chunk = stream.read(); // бинарные данные, мы можем их менять
})
```

В большинстве случаев поток просто переводится в режим `flowing` методом `pipe` и передача работает. Событие `readable` используется крайне редко, руками считывать информацию как правило не нужно.

Нужно иметь ввиду, что имена событий в разных видах потоков могут означать разное. Например, `close` для потока реквеста и чтения файла:

```js
http.createServer((req, res) => {
    req.on('end'); // Считали запрос
    req.on('close'); // Обрыв соединения
});

const stream = fs.ReadStream(path);
stream.on('close'); // Закрыт файл, все вычитали
```

При создании потока на чтение файла открытый файл представляется файловым дескриптором в терминах ОС (типа ссылка на файл).

Для файлового потока на чтение ошибки "обрыв" не будет. Будет просто ошибка.

В объекте `res` (ответ сервера) любые ошибки проглатываются внутри `net.Server`: не при какой ошибке сети событие `error` на `res` не произойдет. Только если после закрытия соединения мы попробуем записать что-то в `res` произойдет ошибка. А так — только `close`. Обычно `error` не обрабатывают на `res`. Только `close`. 

|Ошибка                |Обрыв|
|----------------------|-----|
|`file`                | —   |
|`res`, не обязательно |`res`|

## Проверка наличия фала
Когда открываем поток, то нужно сразу читать, вешать обработчик на ошибку и обрабатывать их по [кодам](https://nodejs.org/api/errors.html#errors_common_system_errors):

```js
const stream = fs.ReadStream();
stream.on('error', (err) => {
    if(err.code === 'ENOENT') {
        // ...
    }
});
```

Функция `fs.stat` и `fs.access` не подходит, когда нужно открыть файл для работы на некоторое время. Она скажет, что файл есть и все. Но в процессе выполнения работы с ним может что-то случиться. Об этом [написано в доках](https://nodejs.org/api/fs.html#fs_fs_access_path_mode_callback). Нужно использовать `fs.open`:

```js

fs.open('myfile', 'r', (err, fd) => { // Проверка на наличие для чтения
// fs.open('myfile', 'wx', (err, fd) => { // ...или для записи
  if (err) {
    if (err.code === 'ENOENT') {
      console.error('myfile does not exist');
      return;
    }

    throw err;
  }

  readMyData(fd); // читаем
  // writeMyData(fd); // ...или записываем
});
```

Налпример, рассмотрим такой код:
```js
fs.stat('/path/to/file.ext', () => {
    const stream = fs.ReadStream();
});
// macrotasks: [fs.stat, ..., fs.ReadStream] В ... может быть что угодно.
```

1. запускаем `fs.stat`.
2. Она асинхронная, попадает в макротаски (требуется дернуть libUV).
3. `fs.ReadStream` может быть запущена не сразу после `fs.stat`. Это асинхронная операция.
4. Между `fs.stat` и `fs.ReadStream` может быть, например `fs.unlink`. И все, пиздец.

Но обычно хватает просто создавать поток и проверять на ошибки. И по кодам ошибок уже писать сообщения и их обработку.

> Как посчитать `Content-Length` (сколько весит файл) для отдачи файла потоком?

Никак. Если читаем файл и пайпим его куда-то, то не факт, что файл будет оставаться неизменным. Поэтому при потоковой передаче данных мы не можем быть уверены, что файл будет неизменным и весить столько, сколко был до начала передачи.

> `.pipe(res)` нужно вызывать в конце, после `.on('open')`, `.on('error')` и пр?

`file.pipe(res)` возвращает объект `res` (!!!), поэтому если дальше чейнить, то будет обрабатывать `res`, а не `file`. Поэтому в большинстве случаев `pipe` должен быть в конце.

## Поток на запись
При открытии создании потока `fs.createWritableStream('/path/to/file.ext)` если файл уже есть, то он будет очищен и перезаписываться.

При создании потока на запись мы можем передать `flags` в объекте опций и указать там, чтоб была ошибка, если файл существует:

```js
const options = {
    flags: 'wx' // w — открыть для записи, x — бросить исключение, если файл уже есть
};
const file = fs.createWriteStream('/path/to/file.ext', options);
file.on('error', (err) => {
    if(err.code === 'EEXIST') {
        // ...
    }
});
```

В документации флаги есть в [описании метода `.open`](https://nodejs.org/api/fs.html#fs_fs_open_path_flags_mode_callback), но они могут передаваться во многие методы.

## Проверка размера файла, который посылает пользователь
Прежде всего нужно смотреть заголовок `Content-Length` запроса. В спецификации сказано:

```
The Content-Length entity-header field indicates the size of the entity-body,
in decimal number of OCTETs, sent to the recipient or, in the case of the HEAD
method, the size of the entity-body that would have been sent had the request
been a GET.
```

Octet — 8 бит. В русском языке обычно говорят байт. Но в информатике байт может быть и 10 и 12 бит, а октет всегда 8. Этот термин применяют в основном в сетевых протоколах, чтоб четко говорить о 8-ми битах.

Объекты `req` и `res` связаны одним подключением. Если сделаем `res.end()`, то и `req` закроется. Ему не надо специально делать `req.destroy()`, если вызван `res.end()`.

Можно навешивать сколько угодно `pipe`, `data` и других методов. Например, поток на чтение можно записывать сразу в несколько потоков на запись.

## Отдать файл для загрузки
Если при отдаче файла поставить mime-type `application/octet-stream`, то браузер начнет скачивать файл. Это подходит, когда мы _не знаем, какой у нас файл (неизвестен mime-type) и хотим, чтобы браузер его сохранил, а не пытался открыть_.

Если мы знаем mime-type файла, то [нужно его указать](http://stackoverflow.com/questions/20508788/do-i-need-content-type-application-octet-stream-for-file-downloadG), а чтобы сказать браузеру, надо ли файл загружать или пытаться показать подойдет инструкция `Content-Disposition`.

## Тестирование
Unit
Integration
E2E

## TODO
* [ ] Познакомиться с потоками выполнения ОС (threads). На Хекслете в [бесплатном курсе про ОС](https://ru.hexlet.io/courses/operating_systems) есть про это. И в [Think OS](http://greenteapress.com/thinkos/html/index.html) можно почитать.
* [ ] Как работает отдача файлов в nGinx? Тоже потоково?

## Вопрос по домашке
Если мы получили `Content-Length` и все ок, размер файла нормальный. Стоит ли еще руками проверять на всякий случай размер файла при записи? Или можно завести переменную, которая будет `true`, если `Content-Length` есть и `false`, если его нет. И проверять руками размер при записи только, когда `Content-Length` не доступен.


```js
switch(req.method) {
    case 'POST': {
        const options = {
            flags: 'wx' // открыть файл на запись и бросить исключение, если он существует
        };
        
        const maxSize = 1024 * 1024;
        let size = 0;

        // Проверяем размер присылаемого файла по заголовку `content-length`
        if (req.headers['content-length'] > maxSize) {
            res.statusCode = 413;
            res.end('Content-Length exceeded limit: ' + size + ' of ' + maxSize);

            break; // так
            // return; // ...или так?
        }

        const file = fs.createWriteStream(filePath, options);
        
        // дальше работаем с потоками...
    }
}
```
